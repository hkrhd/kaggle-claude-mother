{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š EDA (Exploratory Data Analysis)\n",
    "\n",
    "## ç›®çš„\n",
    "- ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æ§‹é€ ã‚’ç†è§£\n",
    "- ç‰¹å¾´é‡ã®åˆ†å¸ƒãƒ»ç›¸é–¢ã‚’åˆ†æ\n",
    "- æ¬ æå€¤ãƒ»å¤–ã‚Œå€¤ã®ç‰¹å®š\n",
    "- ãƒ¢ãƒ‡ãƒªãƒ³ã‚°æ–¹é‡ã®æ±ºå®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# è¨­å®š\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "# TODO: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’é©åˆ‡ã«è¨­å®š\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ãƒ‡ãƒ¼ã‚¿æ¦‚è¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºæœ¬æƒ…å ±\n",
    "display(df_train.head())\n",
    "display(df_train.info())\n",
    "display(df_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æ¬ æå€¤åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¬ æå€¤ã®å¯è¦–åŒ–\n",
    "def plot_missing_values(df, title):\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = missing / len(df) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'column': missing.index,\n",
    "        'missing_count': missing.values,\n",
    "        'missing_percentage': missing_pct.values\n",
    "    })\n",
    "    missing_df = missing_df[missing_df['missing_count'] > 0].sort_values('missing_count', ascending=False)\n",
    "    \n",
    "    if len(missing_df) > 0:\n",
    "        fig = px.bar(missing_df, x='column', y='missing_percentage', \n",
    "                     title=f'{title} - Missing Values (%)')\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(f\"{title}: æ¬ æå€¤ãªã—\")\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "missing_train = plot_missing_values(df_train, 'Train')\n",
    "missing_test = plot_missing_values(df_test, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°åã‚’é©åˆ‡ã«è¨­å®š\n",
    "target_col = 'target'  # å®Ÿéš›ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°åã«å¤‰æ›´\n",
    "\n",
    "if target_col in df_train.columns:\n",
    "    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®åˆ†å¸ƒ\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ \n",
    "    df_train[target_col].hist(bins=50, ax=axes[0])\n",
    "    axes[0].set_title('Target Distribution')\n",
    "    axes[0].set_xlabel(target_col)\n",
    "    \n",
    "    # çµ±è¨ˆæƒ…å ±\n",
    "    axes[1].text(0.1, 0.8, f\"Mean: {df_train[target_col].mean():.4f}\")\n",
    "    axes[1].text(0.1, 0.7, f\"Std: {df_train[target_col].std():.4f}\")\n",
    "    axes[1].text(0.1, 0.6, f\"Min: {df_train[target_col].min():.4f}\")\n",
    "    axes[1].text(0.1, 0.5, f\"Max: {df_train[target_col].max():.4f}\")\n",
    "    axes[1].text(0.1, 0.4, f\"Skew: {df_train[target_col].skew():.4f}\")\n",
    "    axes[1].text(0.1, 0.3, f\"Kurtosis: {df_train[target_col].kurtosis():.4f}\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].set_title('Target Statistics')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°åã‚’ç¢ºèªã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ç‰¹å¾´é‡åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°å€¤ç‰¹å¾´é‡ã¨ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡ã®åˆ†é›¢\n",
    "numeric_features = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = df_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’é™¤å¤–\n",
    "if target_col in numeric_features:\n",
    "    numeric_features.remove(target_col)\n",
    "\n",
    "print(f\"æ•°å€¤ç‰¹å¾´é‡: {len(numeric_features)}å€‹\")\n",
    "print(f\"ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡: {len(categorical_features)}å€‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°å€¤ç‰¹å¾´é‡ã®åˆ†å¸ƒ\n",
    "if len(numeric_features) > 0:\n",
    "    n_cols = 4\n",
    "    n_rows = (len(numeric_features) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5 * n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "    \n",
    "    for i, feature in enumerate(numeric_features[:len(axes)]):\n",
    "        df_train[feature].hist(bins=50, ax=axes[i])\n",
    "        axes[i].set_title(f'{feature}')\n",
    "        axes[i].set_xlabel(feature)\n",
    "    \n",
    "    # ä½™ã£ãŸã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’éè¡¨ç¤º\n",
    "    for i in range(len(numeric_features), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç›¸é–¢åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°å€¤ç‰¹å¾´é‡ã®ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹\n",
    "if len(numeric_features) > 1:\n",
    "    corr_features = numeric_features + ([target_col] if target_col in df_train.columns else [])\n",
    "    correlation_matrix = df_train[corr_features].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, fmt='.2f')\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®ç›¸é–¢ï¼ˆé«˜ã„é †ï¼‰\n",
    "    if target_col in df_train.columns:\n",
    "        target_corr = correlation_matrix[target_col].abs().sort_values(ascending=False)\n",
    "        print(\"\\nã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®ç›¸é–¢ï¼ˆçµ¶å¯¾å€¤ã€é«˜ã„é †ï¼‰:\")\n",
    "        print(target_corr.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡ã®ä¸€æ„å€¤æ•°\n",
    "if len(categorical_features) > 0:\n",
    "    cat_info = pd.DataFrame({\n",
    "        'feature': categorical_features,\n",
    "        'unique_count': [df_train[col].nunique() for col in categorical_features],\n",
    "        'missing_count': [df_train[col].isnull().sum() for col in categorical_features]\n",
    "    })\n",
    "    cat_info = cat_info.sort_values('unique_count', ascending=False)\n",
    "    display(cat_info)\n",
    "    \n",
    "    # é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ç‰¹å¾´é‡ã®ç¢ºèª\n",
    "    high_cardinality = cat_info[cat_info['unique_count'] > 50]['feature'].tolist()\n",
    "    if high_cardinality:\n",
    "        print(f\"\\né«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ç‰¹å¾´é‡ (>50): {high_cardinality}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å¤–ã‚Œå€¤æ¤œå‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°å€¤ç‰¹å¾´é‡ã®å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆIQRæ³•ï¼‰\n",
    "if len(numeric_features) > 0:\n",
    "    outlier_info = []\n",
    "    \n",
    "    for feature in numeric_features:\n",
    "        Q1 = df_train[feature].quantile(0.25)\n",
    "        Q3 = df_train[feature].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = df_train[(df_train[feature] < lower_bound) | (df_train[feature] > upper_bound)]\n",
    "        outlier_count = len(outliers)\n",
    "        outlier_percentage = outlier_count / len(df_train) * 100\n",
    "        \n",
    "        outlier_info.append({\n",
    "            'feature': feature,\n",
    "            'outlier_count': outlier_count,\n",
    "            'outlier_percentage': outlier_percentage,\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound\n",
    "        })\n",
    "    \n",
    "    outlier_df = pd.DataFrame(outlier_info)\n",
    "    outlier_df = outlier_df.sort_values('outlier_percentage', ascending=False)\n",
    "    display(outlier_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "### ç™ºè¦‹ã—ãŸç‰¹å¾´\n",
    "- TODO: EDAçµæœã‚’ã¾ã¨ã‚ã‚‹\n",
    "\n",
    "### å‰å‡¦ç†ãŒå¿…è¦ãªé …ç›®\n",
    "- TODO: æ¬ æå€¤å‡¦ç†\n",
    "- TODO: å¤–ã‚Œå€¤å‡¦ç†\n",
    "- TODO: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\n",
    "\n",
    "### ãƒ¢ãƒ‡ãƒªãƒ³ã‚°æ–¹é‡\n",
    "- TODO: é©ç”¨äºˆå®šã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ \n",
    "- TODO: è©•ä¾¡æŒ‡æ¨™ã®ç¢ºèª\n",
    "- TODO: äº¤å·®æ¤œè¨¼æˆ¦ç•¥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}