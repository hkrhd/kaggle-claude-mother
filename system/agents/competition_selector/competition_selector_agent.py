"""
ç«¶æŠ€é¸æŠã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

ãƒ¡ãƒ€ãƒ«ç²å¾—å¯èƒ½æ€§ãƒ»æˆ¦ç•¥çš„ä¾¡å€¤ãƒ»ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡æ€§ã‚’ç·åˆè©•ä¾¡ã—ã€
LLMãƒ™ãƒ¼ã‚¹ã®æ„æ€æ±ºå®šã«ã‚ˆã‚Šæœ€é©ãªç«¶æŠ€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’é¸æŠã™ã‚‹å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚
"""

import asyncio
import logging
import uuid
import json
from datetime import datetime, timedelta, timezone
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from enum import Enum

# LLMæ¨è«–ã‚·ã‚¹ãƒ†ãƒ 
from openai import AsyncOpenAI
import anthropic

# GitHub Issueé€£æº
from ...issue_safety_system.utils.github_api_wrapper import GitHubApiWrapper
from ...issue_safety_system.concurrency_control.atomic_operations import AtomicIssueOperations

# ç«¶æŠ€ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
from ...dynamic_competition_manager.medal_probability_calculators.medal_probability_calculator import (
    MedalProbabilityCalculator, CompetitionData, CompetitionType, PrizeType
)


class SelectionStrategy(Enum):
    """é¸æŠæˆ¦ç•¥"""
    CONSERVATIVE = "conservative"      # ä¿å®ˆçš„: é«˜ç¢ºç‡ãƒ»ä½ãƒªã‚¹ã‚¯é‡è¦–
    BALANCED = "balanced"             # ãƒãƒ©ãƒ³ã‚¹å‹: ç¢ºç‡ãƒ»ä¾¡å€¤ãƒ»å¤šæ§˜æ€§ãƒãƒ©ãƒ³ã‚¹
    AGGRESSIVE = "aggressive"         # ç©æ¥µçš„: é«˜ä¾¡å€¤ãƒ»é«˜ãƒªã‚¿ãƒ¼ãƒ³è¿½æ±‚
    PORTFOLIO_OPTIMAL = "portfolio_optimal"  # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–


class CompetitionCategory(Enum):
    """ç«¶æŠ€ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
    FEATURED_HIGH_PRIZE = "featured_high"      # Featuredãƒ»é«˜è³é‡‘
    FEATURED_STANDARD = "featured_standard"    # Featuredãƒ»æ¨™æº–è³é‡‘
    RESEARCH_INNOVATION = "research_innovation"  # Researchãƒ»é©æ–°çš„
    RESEARCH_STANDARD = "research_standard"    # Researchãƒ»æ¨™æº–
    TABULAR_MASTERY = "tabular_mastery"       # ãƒ†ãƒ¼ãƒ–ãƒ«ç‰¹åŒ–ãƒ»ç¿’ç†Ÿ
    COMPUTER_VISION = "computer_vision"       # CVå°‚é–€
    NLP_LANGUAGE = "nlp_language"            # NLPå°‚é–€
    TIME_SERIES = "time_series"              # æ™‚ç³»åˆ—å°‚é–€


@dataclass
class CompetitionProfile:
    """ç«¶æŠ€ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«"""
    # åŸºæœ¬æƒ…å ±
    id: str
    name: str
    type: str
    category: CompetitionCategory
    
    # ç«¶æŠ€å±æ€§
    deadline: datetime
    participants: int
    prize_amount: float
    has_medals: bool
    
    # ãƒ¡ãƒ€ãƒ«åˆ†æ
    medal_probability: float
    bronze_probability: float
    silver_probability: float
    gold_probability: float
    
    # æˆ¦ç•¥è©•ä¾¡
    strategic_value: float        # æˆ¦ç•¥çš„ä¾¡å€¤ (0.0-1.0)
    skill_alignment: float        # ã‚¹ã‚­ãƒ«é©åˆåº¦ (0.0-1.0)
    resource_efficiency: float    # ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡ (0.0-1.0)
    portfolio_synergy: float      # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚·ãƒŠã‚¸ãƒ¼ (0.0-1.0)
    
    # ãƒªã‚¹ã‚¯è©•ä¾¡
    technical_risk: float         # æŠ€è¡“å®Ÿè£…ãƒªã‚¹ã‚¯ (0.0-1.0)
    competition_risk: float       # ç«¶åˆãƒ¬ãƒ™ãƒ«ãƒªã‚¹ã‚¯ (0.0-1.0)
    timeline_risk: float          # æ™‚é–“åˆ¶ç´„ãƒªã‚¹ã‚¯ (0.0-1.0)
    
    # æ¨å®šã‚³ã‚¹ãƒˆ
    estimated_gpu_hours: float
    estimated_development_days: float
    confidence_level: float
    
    # LLMåˆ¤æ–­çµæœ
    llm_recommendation: str       # "strongly_recommend" | "recommend" | "neutral" | "avoid"
    llm_reasoning: List[str]
    llm_score: float             # LLMç·åˆã‚¹ã‚³ã‚¢ (0.0-1.0)


@dataclass
class SelectionDecision:
    """é¸æŠæ±ºå®š"""
    decision_id: str
    timestamp: datetime
    strategy: SelectionStrategy
    
    # é¸æŠçµæœ
    selected_competitions: List[CompetitionProfile]
    rejected_competitions: List[CompetitionProfile]
    deferred_competitions: List[CompetitionProfile]
    
    # æ„æ€æ±ºå®šæ ¹æ‹ 
    selection_reasoning: List[str]
    portfolio_optimization: Dict[str, Any]
    resource_allocation: Dict[str, float]
    
    # è©•ä¾¡æŒ‡æ¨™
    expected_medal_count: float
    total_expected_value: float
    portfolio_risk_score: float
    
    # ä¿¡é ¼æ€§
    decision_confidence: float
    llm_consensus_score: float


class CompetitionSelectorAgent:
    """ç«¶æŠ€é¸æŠã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, github_token: str, repo_name: str):
        self.logger = logging.getLogger(__name__)
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæƒ…å ±
        self.agent_id = f"selector-{uuid.uuid4().hex[:8]}"
        self.agent_version = "1.0.0"
        self.start_time = datetime.utcnow()
        
        # LLM ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.openai_client = AsyncOpenAI()  # APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•å–å¾—
        self.anthropic_client = anthropic.AsyncAnthropic()  # APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•å–å¾—
        
        # GitHub Issueé€£æº
        self.github_wrapper = GitHubApiWrapper(
            access_token=github_token,
            repo_name=repo_name
        )
        self.atomic_operations = AtomicIssueOperations(
            github_client=self.github_wrapper.github,
            repo_name=repo_name
        )
        
        # åˆ†æã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.medal_calculator = MedalProbabilityCalculator()
        
        # é¸æŠå±¥æ­´
        self.selection_history: List[SelectionDecision] = []
        self.current_portfolio: List[CompetitionProfile] = []
        
        # è¨­å®š
        self.max_concurrent_competitions = 3
        self.min_medal_probability_threshold = 0.15
        self.max_total_gpu_budget = 120.0  # æ™‚é–“
        self.selection_interval_hours = 12  # é¸æŠå®Ÿè¡Œé–“éš”
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å±¥æ­´ï¼ˆå­¦ç¿’ç”¨ï¼‰
        self.historical_performance: Dict[str, Any] = {}
        
        self.logger.info(f"CompetitionSelectorAgentåˆæœŸåŒ–å®Œäº†: {self.agent_id}")
    
    async def evaluate_available_competitions(
        self,
        available_competitions: List[Dict[str, Any]],
        strategy: SelectionStrategy = SelectionStrategy.BALANCED
    ) -> SelectionDecision:
        """åˆ©ç”¨å¯èƒ½ç«¶æŠ€è©•ä¾¡ãƒ»é¸æŠå®Ÿè¡Œ"""
        
        self.logger.info(f"ç«¶æŠ€é¸æŠè©•ä¾¡é–‹å§‹: {len(available_competitions)}ç«¶æŠ€, æˆ¦ç•¥: {strategy.value}")
        
        decision_id = f"decision-{uuid.uuid4().hex[:8]}"
        
        try:
            # 1. ç«¶æŠ€ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
            competition_profiles = []
            for comp_data in available_competitions:
                profile = await self._create_competition_profile(comp_data)
                competition_profiles.append(profile)
            
            # 2. LLMç·åˆè©•ä¾¡å®Ÿè¡Œ
            llm_evaluated_profiles = await self._perform_llm_evaluation(
                competition_profiles, strategy
            )
            
            # 3. ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–
            optimization_result = await self._optimize_competition_portfolio(
                llm_evaluated_profiles, strategy
            )
            
            # 4. æœ€çµ‚é¸æŠæ±ºå®š
            decision = await self._make_final_selection_decision(
                decision_id, llm_evaluated_profiles, optimization_result, strategy
            )
            
            # 5. é¸æŠãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»GitHub Issueä½œæˆ
            await self._create_selection_report(decision)
            
            # 6. å±¥æ­´æ›´æ–°
            self.selection_history.append(decision)
            self.current_portfolio = decision.selected_competitions
            
            self.logger.info(f"ç«¶æŠ€é¸æŠå®Œäº†: {len(decision.selected_competitions)}ç«¶æŠ€é¸æŠ")
            
            return decision
            
        except Exception as e:
            self.logger.error(f"ç«¶æŠ€é¸æŠè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ±ºå®š
            fallback_decision = SelectionDecision(
                decision_id=decision_id,
                timestamp=datetime.utcnow(),
                strategy=strategy,
                selected_competitions=[],
                rejected_competitions=[],
                deferred_competitions=[],
                selection_reasoning=[f"è©•ä¾¡ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {str(e)}"],
                portfolio_optimization={},
                resource_allocation={},
                expected_medal_count=0.0,
                total_expected_value=0.0,
                portfolio_risk_score=1.0,
                decision_confidence=0.0,
                llm_consensus_score=0.0
            )
            
            return fallback_decision
    
    async def _create_competition_profile(self, comp_data: Dict[str, Any]) -> CompetitionProfile:
        """ç«¶æŠ€ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
        
        try:
            # åŸºæœ¬æƒ…å ±æŠ½å‡º
            comp_id = comp_data.get("id", "unknown")
            comp_name = comp_data.get("name", "Unknown Competition")
            comp_type = comp_data.get("type", "tabular")
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
            category = await self._classify_competition_category(comp_data)
            
            # ãƒ¡ãƒ€ãƒ«ç¢ºç‡ç®—å‡º
            medal_probs = await self._calculate_detailed_medal_probabilities(comp_data)
            
            # æˆ¦ç•¥è©•ä¾¡æŒ‡æ¨™ç®—å‡º
            strategic_metrics = await self._calculate_strategic_metrics(comp_data, comp_type)
            
            # ãƒªã‚¹ã‚¯è©•ä¾¡
            risk_metrics = await self._assess_competition_risks(comp_data, comp_type)
            
            # ãƒªã‚½ãƒ¼ã‚¹æ¨å®š
            resource_estimates = await self._estimate_resource_requirements(comp_data, comp_type)
            
            profile = CompetitionProfile(
                id=comp_id,
                name=comp_name,
                type=comp_type,
                category=category,
                deadline=datetime.fromisoformat(comp_data.get("deadline", datetime.utcnow().isoformat())),
                participants=comp_data.get("participants", 1000),
                prize_amount=comp_data.get("prize_amount", 0.0),
                has_medals=comp_data.get("awards_medals", True),
                
                medal_probability=medal_probs["overall"],
                bronze_probability=medal_probs["bronze"],
                silver_probability=medal_probs["silver"],
                gold_probability=medal_probs["gold"],
                
                strategic_value=strategic_metrics["strategic_value"],
                skill_alignment=strategic_metrics["skill_alignment"],
                resource_efficiency=strategic_metrics["resource_efficiency"],
                portfolio_synergy=strategic_metrics["portfolio_synergy"],
                
                technical_risk=risk_metrics["technical_risk"],
                competition_risk=risk_metrics["competition_risk"],
                timeline_risk=risk_metrics["timeline_risk"],
                
                estimated_gpu_hours=resource_estimates["gpu_hours"],
                estimated_development_days=resource_estimates["development_days"],
                confidence_level=strategic_metrics["confidence_level"],
                
                # LLMè©•ä¾¡ã¯å¾Œã§å®Ÿè¡Œ
                llm_recommendation="neutral",
                llm_reasoning=[],
                llm_score=0.5
            )
            
            return profile
            
        except Exception as e:
            self.logger.error(f"ç«¶æŠ€ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼ {comp_data.get('name', 'Unknown')}: {e}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
            return CompetitionProfile(
                id=comp_data.get("id", "error"),
                name=comp_data.get("name", "Error Competition"),
                type="tabular",
                category=CompetitionCategory.FEATURED_STANDARD,
                deadline=datetime.utcnow() + timedelta(days=30),
                participants=1000,
                prize_amount=0.0,
                has_medals=False,
                medal_probability=0.0,
                bronze_probability=0.0,
                silver_probability=0.0,
                gold_probability=0.0,
                strategic_value=0.0,
                skill_alignment=0.0,
                resource_efficiency=0.0,
                portfolio_synergy=0.0,
                technical_risk=1.0,
                competition_risk=1.0,
                timeline_risk=1.0,
                estimated_gpu_hours=0.0,
                estimated_development_days=0.0,
                confidence_level=0.0,
                llm_recommendation="avoid",
                llm_reasoning=["ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼"],
                llm_score=0.0
            )
    
    async def _classify_competition_category(self, comp_data: Dict[str, Any]) -> CompetitionCategory:
        """ç«¶æŠ€ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
        
        comp_type = comp_data.get("type", "tabular")
        prize_amount = comp_data.get("prize_amount", 0.0)
        category = comp_data.get("competition_category", "").lower()
        
        # Featured competitions
        if category == "featured":
            if prize_amount >= 50000:
                return CompetitionCategory.FEATURED_HIGH_PRIZE
            else:
                return CompetitionCategory.FEATURED_STANDARD
        
        # Research competitions
        elif category == "research":
            # é©æ–°æ€§åˆ¤å®šï¼ˆç°¡æ˜“ç‰ˆ - å®Ÿéš›ã«ã¯ã‚ˆã‚Šè©³ç´°ãªåˆ†æãŒå¿…è¦ï¼‰
            name_lower = comp_data.get("name", "").lower()
            if any(keyword in name_lower for keyword in ["novel", "new", "innovative", "breakthrough"]):
                return CompetitionCategory.RESEARCH_INNOVATION
            else:
                return CompetitionCategory.RESEARCH_STANDARD
        
        # Type-based classification
        elif comp_type == "tabular":
            return CompetitionCategory.TABULAR_MASTERY
        elif comp_type == "computer_vision":
            return CompetitionCategory.COMPUTER_VISION
        elif comp_type in ["nlp", "text"]:
            return CompetitionCategory.NLP_LANGUAGE
        elif comp_type == "time_series":
            return CompetitionCategory.TIME_SERIES
        
        else:
            return CompetitionCategory.FEATURED_STANDARD
    
    async def _calculate_detailed_medal_probabilities(self, comp_data: Dict[str, Any]) -> Dict[str, float]:
        """è©³ç´°ãƒ¡ãƒ€ãƒ«ç¢ºç‡ç®—å‡º"""
        
        try:
            # CompetitionDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆï¼ˆæ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯æ´»ç”¨ï¼‰
            comp_type_mapping = {
                "tabular": CompetitionType.TABULAR,
                "computer_vision": CompetitionType.COMPUTER_VISION,
                "nlp": CompetitionType.NLP,
                "time_series": CompetitionType.TIME_SERIES
            }
            
            comp_type = comp_type_mapping.get(comp_data.get("type", "tabular"), CompetitionType.TABULAR)
            prize_amount = comp_data.get("prize_amount", 0.0)
            
            competition_data = CompetitionData(
                competition_id=comp_data.get("id", "unknown"),
                title=comp_data.get("name", "Unknown"),
                competition_type=comp_type,
                participant_count=comp_data.get("participants", 1000),
                total_prize=prize_amount,
                prize_type=PrizeType.MONETARY if prize_amount > 0 else PrizeType.KNOWLEDGE,
                days_remaining=(datetime.fromisoformat(comp_data.get("deadline", datetime.utcnow().isoformat())).replace(tzinfo=timezone.utc) - datetime.now(timezone.utc)).days,
                data_characteristics={
                    "dataset_size": "medium",
                    "feature_count": 50 if comp_type == CompetitionType.TABULAR else 1000,
                    "data_quality": "high"
                },
                skill_requirements=["feature_engineering", "ensemble_methods"] if comp_type == CompetitionType.TABULAR else ["deep_learning"],
                leaderboard_competition=min(1.0, comp_data.get("participants", 1000) / 2000)
            )
            
            # å…¨ä½“ãƒ¡ãƒ€ãƒ«ç¢ºç‡ç®—å‡º
            result = await self.medal_calculator.calculate_medal_probability(competition_data)
            overall_prob = result.overall_medal_probability
            
            # ãƒ¡ãƒ€ãƒ«åˆ¥ç¢ºç‡æ¨å®šï¼ˆç°¡æ˜“ãƒ¢ãƒ‡ãƒ«ï¼‰
            # é€šå¸¸ã€Bronze > Silver > Gold ã®é †ã§ç¢ºç‡ãŒä¸‹ãŒã‚‹
            bronze_prob = overall_prob * 0.6  # å…¨ä½“ç¢ºç‡ã®60%
            silver_prob = overall_prob * 0.3   # å…¨ä½“ç¢ºç‡ã®30%
            gold_prob = overall_prob * 0.1     # å…¨ä½“ç¢ºç‡ã®10%
            
            return {
                "overall": overall_prob,
                "bronze": bronze_prob,
                "silver": silver_prob,
                "gold": gold_prob
            }
            
        except Exception as e:
            self.logger.error(f"ãƒ¡ãƒ€ãƒ«ç¢ºç‡ç®—å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "overall": 0.0,
                "bronze": 0.0,
                "silver": 0.0,
                "gold": 0.0
            }
    
    async def _calculate_strategic_metrics(self, comp_data: Dict[str, Any], comp_type: str) -> Dict[str, float]:
        """æˆ¦ç•¥è©•ä¾¡æŒ‡æ¨™ç®—å‡º"""
        
        try:
            # æˆ¦ç•¥çš„ä¾¡å€¤ç®—å‡º
            prize_amount = comp_data.get("prize_amount", 0.0)
            participants = comp_data.get("participants", 1000)
            
            # è³é‡‘ä¾¡å€¤æ­£è¦åŒ– (0-1)
            prize_value = min(1.0, prize_amount / 100000)  # $100k ã‚’åŸºæº–ã¨ã—ãŸæ­£è¦åŒ–
            
            # ç«¶äº‰å¯†åº¦èª¿æ•´ (å‚åŠ è€…ãŒå¤šã™ãã‚‹ã¨ä¾¡å€¤ä½ä¸‹)
            competition_density = max(0.1, 1.0 - (participants - 1000) / 10000)
            
            strategic_value = (prize_value * 0.7 + competition_density * 0.3)
            
            # ã‚¹ã‚­ãƒ«é©åˆåº¦ (ç«¶æŠ€ã‚¿ã‚¤ãƒ—åˆ¥)
            skill_alignment_map = {
                "tabular": 0.9,      # æœ€ã‚‚å¾—æ„
                "computer_vision": 0.7,
                "nlp": 0.6,
                "time_series": 0.8,
                "audio": 0.5,
                "graph": 0.4
            }
            skill_alignment = skill_alignment_map.get(comp_type, 0.5)
            
            # ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡æ€§ (è³é‡‘/äºˆæƒ³å·¥æ•°æ¯”)
            estimated_hours = max(40, participants / 50)  # å‚åŠ è€…æ•°ãƒ™ãƒ¼ã‚¹ã®å·¥æ•°æ¨å®š
            resource_efficiency = min(1.0, (prize_amount / max(1, estimated_hours)) / 100)
            
            # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚·ãƒŠã‚¸ãƒ¼ (ç¾åœ¨ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¨ã®çµ„ã¿åˆã‚ã›åŠ¹æœ)
            current_types = [comp.type for comp in self.current_portfolio]
            type_diversity_bonus = 0.2 if comp_type not in current_types else 0.0
            portfolio_synergy = 0.5 + type_diversity_bonus
            
            # ä¿¡é ¼åº¦ (ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ€§ã«åŸºã¥ã)
            data_completeness = 1.0 if all(key in comp_data for key in ["name", "type", "deadline", "participants"]) else 0.7
            confidence_level = data_completeness
            
            return {
                "strategic_value": strategic_value,
                "skill_alignment": skill_alignment,
                "resource_efficiency": resource_efficiency,
                "portfolio_synergy": portfolio_synergy,
                "confidence_level": confidence_level
            }
            
        except Exception as e:
            self.logger.error(f"æˆ¦ç•¥æŒ‡æ¨™ç®—å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "strategic_value": 0.0,
                "skill_alignment": 0.0,
                "resource_efficiency": 0.0,
                "portfolio_synergy": 0.0,
                "confidence_level": 0.0
            }
    
    async def _assess_competition_risks(self, comp_data: Dict[str, Any], comp_type: str) -> Dict[str, float]:
        """ç«¶æŠ€ãƒªã‚¹ã‚¯è©•ä¾¡"""
        
        try:
            participants = comp_data.get("participants", 1000)
            deadline = datetime.fromisoformat(comp_data.get("deadline", datetime.utcnow().isoformat()))
            days_remaining = (deadline - datetime.utcnow()).days
            
            # æŠ€è¡“å®Ÿè£…ãƒªã‚¹ã‚¯
            technical_risk_map = {
                "tabular": 0.2,      # ä½ãƒªã‚¹ã‚¯
                "computer_vision": 0.5,  # ä¸­ãƒªã‚¹ã‚¯
                "nlp": 0.6,          # é«˜ãƒªã‚¹ã‚¯
                "time_series": 0.4,
                "audio": 0.8,        # éå¸¸ã«é«˜ãƒªã‚¹ã‚¯
                "graph": 0.7
            }
            technical_risk = technical_risk_map.get(comp_type, 0.5)
            
            # ç«¶åˆãƒ¬ãƒ™ãƒ«ãƒªã‚¹ã‚¯ (å‚åŠ è€…æ•°ãƒ™ãƒ¼ã‚¹)
            if participants < 500:
                competition_risk = 0.2    # ä½ç«¶åˆ
            elif participants < 2000:
                competition_risk = 0.4    # ä¸­ç«¶åˆ
            elif participants < 5000:
                competition_risk = 0.7    # é«˜ç«¶åˆ
            else:
                competition_risk = 0.9    # è¶…é«˜ç«¶åˆ
            
            # æ™‚é–“åˆ¶ç´„ãƒªã‚¹ã‚¯
            if days_remaining > 60:
                timeline_risk = 0.1      # ååˆ†ãªæ™‚é–“
            elif days_remaining > 30:
                timeline_risk = 0.3      # é©åº¦ãªæ™‚é–“
            elif days_remaining > 14:
                timeline_risk = 0.6      # æ™‚é–“åˆ¶ç´„ã‚ã‚Š
            else:
                timeline_risk = 0.9      # å³é‡ãªæ™‚é–“åˆ¶ç´„
            
            return {
                "technical_risk": technical_risk,
                "competition_risk": competition_risk,
                "timeline_risk": timeline_risk
            }
            
        except Exception as e:
            self.logger.error(f"ãƒªã‚¹ã‚¯è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "technical_risk": 0.5,
                "competition_risk": 0.5,
                "timeline_risk": 0.5
            }
    
    async def _estimate_resource_requirements(self, comp_data: Dict[str, Any], comp_type: str) -> Dict[str, float]:
        """ãƒªã‚½ãƒ¼ã‚¹è¦ä»¶æ¨å®š"""
        
        try:
            participants = comp_data.get("participants", 1000)
            
            # GPUæ™‚é–“æ¨å®š (ç«¶æŠ€ã‚¿ã‚¤ãƒ—ãƒ»å‚åŠ è€…æ•°ãƒ™ãƒ¼ã‚¹)
            base_gpu_hours = {
                "tabular": 8,
                "computer_vision": 24,
                "nlp": 20,
                "time_series": 12,
                "audio": 30,
                "graph": 16
            }
            
            base_hours = base_gpu_hours.get(comp_type, 8)
            
            # å‚åŠ è€…æ•°ã«ã‚ˆã‚‹èª¿æ•´ (ç«¶äº‰ãŒæ¿€ã—ã„ã»ã©ã‚ˆã‚Šå¤šãã®ãƒªã‚½ãƒ¼ã‚¹ãŒå¿…è¦)
            competition_multiplier = 1.0 + (participants - 1000) / 5000
            
            estimated_gpu_hours = base_hours * max(1.0, competition_multiplier)
            
            # é–‹ç™ºæ—¥æ•°æ¨å®š
            estimated_development_days = max(7, estimated_gpu_hours / 3)  # 1æ—¥3æ™‚é–“ã®ä½œæ¥­æƒ³å®š
            
            return {
                "gpu_hours": estimated_gpu_hours,
                "development_days": estimated_development_days
            }
            
        except Exception as e:
            self.logger.error(f"ãƒªã‚½ãƒ¼ã‚¹æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "gpu_hours": 10.0,
                "development_days": 7.0
            }
    
    async def _perform_llm_evaluation(
        self,
        profiles: List[CompetitionProfile],
        strategy: SelectionStrategy
    ) -> List[CompetitionProfile]:
        """LLMç·åˆè©•ä¾¡å®Ÿè¡Œ"""
        
        self.logger.info(f"LLMè©•ä¾¡é–‹å§‹: {len(profiles)}ç«¶æŠ€")
        
        # ä¸¦åˆ—LLMè©•ä¾¡å®Ÿè¡Œ
        llm_tasks = []
        for profile in profiles:
            task = self._evaluate_single_competition_with_llm(profile, strategy)
            llm_tasks.append(task)
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        llm_results = await asyncio.gather(*llm_tasks, return_exceptions=True)
        
        # çµæœçµ±åˆ
        evaluated_profiles = []
        for i, (profile, result) in enumerate(zip(profiles, llm_results)):
            if isinstance(result, Exception):
                self.logger.error(f"LLMè©•ä¾¡å¤±æ•— {profile.name}: {result}")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
                evaluated_profiles.append(profile)
            else:
                evaluated_profiles.append(result)
        
        self.logger.info(f"LLMè©•ä¾¡å®Œäº†: {len(evaluated_profiles)}ç«¶æŠ€")
        return evaluated_profiles
    
    async def _evaluate_single_competition_with_llm(
        self,
        profile: CompetitionProfile,
        strategy: SelectionStrategy
    ) -> CompetitionProfile:
        """å˜ä¸€ç«¶æŠ€LLMè©•ä¾¡"""
        
        try:
            # LLMè©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
            evaluation_prompt = self._create_competition_evaluation_prompt(profile, strategy)
            
            # Claude (Anthropic) ã§è©•ä¾¡å®Ÿè¡Œ
            response = await self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=1000,
                temperature=0.1,
                messages=[
                    {
                        "role": "user",
                        "content": evaluation_prompt
                    }
                ]
            )
            
            # å›ç­”è§£æ
            llm_evaluation = self._parse_llm_evaluation_response(response.content[0].text)
            
            # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
            profile.llm_recommendation = llm_evaluation["recommendation"]
            profile.llm_reasoning = llm_evaluation["reasoning"]
            profile.llm_score = llm_evaluation["score"]
            
            return profile
            
        except Exception as e:
            self.logger.error(f"LLMè©•ä¾¡ã‚¨ãƒ©ãƒ¼ {profile.name}: {e}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè©•ä¾¡
            profile.llm_recommendation = "neutral"
            profile.llm_reasoning = [f"LLMè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}"]
            profile.llm_score = 0.5
            
            return profile
    
    def _create_competition_evaluation_prompt(
        self,
        profile: CompetitionProfile,
        strategy: SelectionStrategy
    ) -> str:
        """ç«¶æŠ€è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        
        # ç¾åœ¨ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæƒ…å ±
        current_portfolio_info = ""
        if self.current_portfolio:
            current_portfolio_info = f"""
ç¾åœ¨ã®ç«¶æŠ€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª:
{chr(10).join([f"- {comp.name} ({comp.type}, ãƒ¡ãƒ€ãƒ«ç¢ºç‡: {comp.medal_probability:.1%})" for comp in self.current_portfolio])}
"""
        
        # æˆ¦ç•¥åˆ¥ã®é‡è¦–ãƒã‚¤ãƒ³ãƒˆ
        strategy_focus = {
            SelectionStrategy.CONSERVATIVE: "ãƒ¡ãƒ€ãƒ«ç¢ºç‡ãƒ»å®‰å…¨æ€§ã‚’æœ€é‡è¦–ã€‚ãƒªã‚¹ã‚¯ã‚’é¿ã‘ã¦ç¢ºå®Ÿãªæˆæœã‚’ç‹™ã†ã€‚",
            SelectionStrategy.BALANCED: "ãƒ¡ãƒ€ãƒ«ç¢ºç‡ãƒ»ä¾¡å€¤ãƒ»å¤šæ§˜æ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’é‡è¦–ã€‚ãƒªã‚¹ã‚¯ã¨åç›Šã®æœ€é©åŒ–ã€‚",
            SelectionStrategy.AGGRESSIVE: "é«˜ä¾¡å€¤ãƒ»é«˜ãƒªã‚¿ãƒ¼ãƒ³ã‚’æœ€é‡è¦–ã€‚ãƒªã‚¹ã‚¯ã‚’è¨±å®¹ã—ã¦å¤§ããªæˆæœã‚’ç‹™ã†ã€‚",
            SelectionStrategy.PORTFOLIO_OPTIMAL: "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“ã®æœ€é©åŒ–ã‚’é‡è¦–ã€‚åˆ†æ•£åŠ¹æœãƒ»ã‚·ãƒŠã‚¸ãƒ¼ã‚’è€ƒæ…®ã€‚"
        }
        
        current_strategy_focus = strategy_focus.get(strategy, "ãƒãƒ©ãƒ³ã‚¹é‡è¦–")
        
        prompt = f"""ã‚ãªãŸã¯Kaggleç«¶æŠ€é¸æŠã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ç«¶æŠ€ã‚’è©•ä¾¡ã—ã€å‚åŠ ã™ã¹ãã‹ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚

## é¸æŠæˆ¦ç•¥
{current_strategy_focus}

## è©•ä¾¡å¯¾è±¡ç«¶æŠ€
**ç«¶æŠ€å**: {profile.name}
**ç¨®é¡**: {profile.type}
**ã‚«ãƒ†ã‚´ãƒª**: {profile.category.value}
**ç· åˆ‡**: {profile.deadline.strftime('%Y-%m-%d')} ({(profile.deadline - datetime.utcnow()).days}æ—¥å¾Œ)
**å‚åŠ è€…æ•°**: {profile.participants:,}å
**è³é‡‘**: ${profile.prize_amount:,.0f}
**ãƒ¡ãƒ€ãƒ«å¯¾è±¡**: {'æœ‰' if profile.has_medals else 'ç„¡'}

## åˆ†æçµæœ
**ãƒ¡ãƒ€ãƒ«ç¢ºç‡**: å…¨ä½“{profile.medal_probability:.1%} (é‡‘{profile.gold_probability:.1%}/éŠ€{profile.silver_probability:.1%}/éŠ…{profile.bronze_probability:.1%})
**æˆ¦ç•¥çš„ä¾¡å€¤**: {profile.strategic_value:.2f}
**ã‚¹ã‚­ãƒ«é©åˆåº¦**: {profile.skill_alignment:.2f}
**ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡**: {profile.resource_efficiency:.2f}
**ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚·ãƒŠã‚¸ãƒ¼**: {profile.portfolio_synergy:.2f}

## ãƒªã‚¹ã‚¯è©•ä¾¡
**æŠ€è¡“ãƒªã‚¹ã‚¯**: {profile.technical_risk:.2f}
**ç«¶åˆãƒªã‚¹ã‚¯**: {profile.competition_risk:.2f}
**æ™‚é–“ãƒªã‚¹ã‚¯**: {profile.timeline_risk:.2f}

## ãƒªã‚½ãƒ¼ã‚¹æ¨å®š
**GPUæ™‚é–“**: {profile.estimated_gpu_hours:.1f}æ™‚é–“
**é–‹ç™ºæœŸé–“**: {profile.estimated_development_days:.1f}æ—¥
**åˆ†æä¿¡é ¼åº¦**: {profile.confidence_level:.1%}

{current_portfolio_info}

## ã‚·ã‚¹ãƒ†ãƒ åˆ¶ç´„
- æœ€å¤§åŒæ™‚ç«¶æŠ€æ•°: {self.max_concurrent_competitions}ç«¶æŠ€
- ç·GPUäºˆç®—: {self.max_total_gpu_budget}æ™‚é–“
- æœ€ä½ãƒ¡ãƒ€ãƒ«ç¢ºç‡: {self.min_medal_probability_threshold:.1%}

ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å›ç­”ã—ã¦ãã ã•ã„:

RECOMMENDATION: [strongly_recommend|recommend|neutral|avoid]
SCORE: [0.0-1.0ã®æ•°å€¤]
REASONING:
- ç†ç”±1
- ç†ç”±2
- ç†ç”±3

æˆ¦ç•¥çš„è¦³ç‚¹ã‹ã‚‰ã€ã“ã®ç«¶æŠ€ã¸ã®å‚åŠ ã‚’æ¨å¥¨ã—ã¾ã™ã‹ï¼Ÿå…·ä½“çš„ãªç†ç”±ã¨å…±ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"""

        return prompt
    
    def _parse_llm_evaluation_response(self, response_text: str) -> Dict[str, Any]:
        """LLMè©•ä¾¡å›ç­”è§£æ"""
        
        try:
            lines = response_text.strip().split('\n')
            
            recommendation = "neutral"
            score = 0.5
            reasoning = []
            
            current_section = None
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                if line.startswith("RECOMMENDATION:"):
                    recommendation = line.split(":", 1)[1].strip().lower()
                elif line.startswith("SCORE:"):
                    try:
                        score = float(line.split(":", 1)[1].strip())
                        score = max(0.0, min(1.0, score))  # 0.0-1.0ã«ã‚¯ãƒ©ãƒ³ãƒ—
                    except ValueError:
                        score = 0.5
                elif line.startswith("REASONING:"):
                    current_section = "reasoning"
                elif current_section == "reasoning" and line.startswith("- "):
                    reasoning.append(line[2:])  # "- "ã‚’é™¤å»
            
            # æ¨å¥¨ãƒ¬ãƒ™ãƒ«æ­£è¦åŒ–
            valid_recommendations = ["strongly_recommend", "recommend", "neutral", "avoid"]
            if recommendation not in valid_recommendations:
                recommendation = "neutral"
            
            return {
                "recommendation": recommendation,
                "score": score,
                "reasoning": reasoning if reasoning else ["LLMè©•ä¾¡è§£æã‚¨ãƒ©ãƒ¼"]
            }
            
        except Exception as e:
            self.logger.error(f"LLMè©•ä¾¡è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "recommendation": "neutral",
                "score": 0.5,
                "reasoning": [f"è©•ä¾¡è§£æã‚¨ãƒ©ãƒ¼: {str(e)}"]
            }
    
    async def _optimize_competition_portfolio(
        self,
        profiles: List[CompetitionProfile],
        strategy: SelectionStrategy
    ) -> Dict[str, Any]:
        """ç«¶æŠ€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–"""
        
        self.logger.info("ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–å®Ÿè¡Œ")
        
        try:
            # åˆ¶ç´„æ¡ä»¶
            max_competitions = self.max_concurrent_competitions
            max_gpu_budget = self.max_total_gpu_budget
            min_medal_prob = self.min_medal_probability_threshold
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            eligible_profiles = [
                p for p in profiles 
                if p.medal_probability >= min_medal_prob and p.llm_recommendation in ["strongly_recommend", "recommend"]
            ]
            
            if not eligible_profiles:
                # åŸºæº–ã‚’æº€ãŸã™ç«¶æŠ€ãŒãªã„å ´åˆã€åŸºæº–ã‚’ç·©å’Œ
                eligible_profiles = [p for p in profiles if p.medal_probability >= min_medal_prob * 0.5]
            
            # æˆ¦ç•¥åˆ¥æœ€é©åŒ–
            if strategy == SelectionStrategy.CONSERVATIVE:
                # é«˜ç¢ºç‡ãƒ»ä½ãƒªã‚¹ã‚¯å„ªå…ˆ
                eligible_profiles.sort(
                    key=lambda p: (p.medal_probability * (1 - p.technical_risk) * (1 - p.timeline_risk)), 
                    reverse=True
                )
            
            elif strategy == SelectionStrategy.AGGRESSIVE:
                # é«˜ä¾¡å€¤ãƒ»é«˜ãƒªã‚¿ãƒ¼ãƒ³å„ªå…ˆ
                eligible_profiles.sort(
                    key=lambda p: (p.strategic_value * p.llm_score * (p.gold_probability + p.silver_probability * 0.5)),
                    reverse=True
                )
            
            elif strategy == SelectionStrategy.PORTFOLIO_OPTIMAL:
                # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚·ãƒŠã‚¸ãƒ¼ãƒ»åˆ†æ•£åŠ¹æœå„ªå…ˆ
                eligible_profiles.sort(
                    key=lambda p: (p.portfolio_synergy * p.medal_probability * p.skill_alignment),
                    reverse=True
                )
            
            else:  # BALANCED
                # ãƒãƒ©ãƒ³ã‚¹ã‚¹ã‚³ã‚¢ç®—å‡º
                for profile in eligible_profiles:
                    balance_score = (
                        profile.medal_probability * 0.3 +
                        profile.strategic_value * 0.25 +
                        profile.llm_score * 0.2 +
                        profile.skill_alignment * 0.15 +
                        (1 - profile.technical_risk) * 0.1
                    )
                    profile.balance_score = balance_score
                
                eligible_profiles.sort(key=lambda p: p.balance_score, reverse=True)
            
            # ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„ã«ã‚ˆã‚‹é¸æŠ
            selected_profiles = []
            total_gpu_hours = 0.0
            
            for profile in eligible_profiles:
                if (len(selected_profiles) < max_competitions and 
                    total_gpu_hours + profile.estimated_gpu_hours <= max_gpu_budget):
                    
                    selected_profiles.append(profile)
                    total_gpu_hours += profile.estimated_gpu_hours
            
            # æœ€é©åŒ–çµæœ
            optimization_result = {
                "strategy": strategy.value,
                "eligible_count": len(eligible_profiles),
                "selected_count": len(selected_profiles),
                "total_gpu_hours": total_gpu_hours,
                "gpu_utilization": total_gpu_hours / max_gpu_budget,
                "expected_medals": sum(p.medal_probability for p in selected_profiles),
                "total_strategic_value": sum(p.strategic_value for p in selected_profiles),
                "portfolio_diversity": len(set(p.type for p in selected_profiles)),
                "avg_confidence": sum(p.confidence_level for p in selected_profiles) / max(1, len(selected_profiles))
            }
            
            self.logger.info(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–å®Œäº†: {len(selected_profiles)}ç«¶æŠ€é¸æŠ")
            
            return optimization_result
            
        except Exception as e:
            self.logger.error(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "strategy": strategy.value,
                "eligible_count": 0,
                "selected_count": 0,
                "error": str(e)
            }
    
    async def _make_final_selection_decision(
        self,
        decision_id: str,
        profiles: List[CompetitionProfile],
        optimization_result: Dict[str, Any],
        strategy: SelectionStrategy
    ) -> SelectionDecision:
        """æœ€çµ‚é¸æŠæ±ºå®š"""
        
        try:
            # æœ€é©åŒ–çµæœã‹ã‚‰é¸æŠæ¸ˆã¿ç«¶æŠ€ã‚’æŠ½å‡º
            selected_profiles = []
            rejected_profiles = []
            deferred_profiles = []
            
            # é¸æŠãƒ­ã‚¸ãƒƒã‚¯
            min_medal_prob = self.min_medal_probability_threshold
            
            for profile in profiles:
                if (profile.llm_recommendation == "strongly_recommend" or
                    (profile.llm_recommendation == "recommend" and profile.medal_probability >= min_medal_prob)):
                    
                    if len(selected_profiles) < self.max_concurrent_competitions:
                        selected_profiles.append(profile)
                    else:
                        deferred_profiles.append(profile)
                
                elif profile.llm_recommendation == "avoid" or profile.medal_probability < min_medal_prob * 0.5:
                    rejected_profiles.append(profile)
                
                else:
                    deferred_profiles.append(profile)
            
            # é¸æŠç†ç”±ç”Ÿæˆ
            selection_reasoning = [
                f"{strategy.value}æˆ¦ç•¥ã«åŸºã¥ãé¸æŠå®Ÿè¡Œ",
                f"{len(selected_profiles)}ç«¶æŠ€ã‚’é¸æŠ (æœ€å¤§{self.max_concurrent_competitions})",
                f"ç·äºˆæƒ³ãƒ¡ãƒ€ãƒ«æ•°: {sum(p.medal_probability for p in selected_profiles):.2f}",
                f"LLMæ¨å¥¨ç«¶æŠ€ã‚’å„ªå…ˆé¸æŠ"
            ]
            
            if optimization_result.get("error"):
                selection_reasoning.append(f"æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {optimization_result['error']}")
            
            # ãƒªã‚½ãƒ¼ã‚¹é…åˆ†
            total_gpu_hours = sum(p.estimated_gpu_hours for p in selected_profiles)
            resource_allocation = {
                "total_gpu_hours": total_gpu_hours,
                "gpu_utilization": total_gpu_hours / self.max_total_gpu_budget,
                "competitions_count": len(selected_profiles),
                "avg_development_days": sum(p.estimated_development_days for p in selected_profiles) / max(1, len(selected_profiles))
            }
            
            # è©•ä¾¡æŒ‡æ¨™ç®—å‡º
            expected_medal_count = sum(p.medal_probability for p in selected_profiles)
            total_expected_value = sum(p.strategic_value * p.medal_probability for p in selected_profiles)
            portfolio_risk_score = sum(p.technical_risk * p.competition_risk for p in selected_profiles) / max(1, len(selected_profiles))
            
            # ä¿¡é ¼æ€§è©•ä¾¡
            decision_confidence = sum(p.confidence_level for p in selected_profiles) / max(1, len(selected_profiles))
            llm_consensus_score = sum(1 for p in selected_profiles if p.llm_recommendation in ["strongly_recommend", "recommend"]) / max(1, len(profiles))
            
            decision = SelectionDecision(
                decision_id=decision_id,
                timestamp=datetime.utcnow(),
                strategy=strategy,
                selected_competitions=selected_profiles,
                rejected_competitions=rejected_profiles,
                deferred_competitions=deferred_profiles,
                selection_reasoning=selection_reasoning,
                portfolio_optimization=optimization_result,
                resource_allocation=resource_allocation,
                expected_medal_count=expected_medal_count,
                total_expected_value=total_expected_value,
                portfolio_risk_score=portfolio_risk_score,
                decision_confidence=decision_confidence,
                llm_consensus_score=llm_consensus_score
            )
            
            return decision
            
        except Exception as e:
            self.logger.error(f"æœ€çµ‚é¸æŠæ±ºå®šã‚¨ãƒ©ãƒ¼: {e}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ç©ºæ±ºå®š
            return SelectionDecision(
                decision_id=decision_id,
                timestamp=datetime.utcnow(),
                strategy=strategy,
                selected_competitions=[],
                rejected_competitions=[],
                deferred_competitions=profiles,
                selection_reasoning=[f"æ±ºå®šã‚¨ãƒ©ãƒ¼: {str(e)}"],
                portfolio_optimization={},
                resource_allocation={},
                expected_medal_count=0.0,
                total_expected_value=0.0,
                portfolio_risk_score=1.0,
                decision_confidence=0.0,
                llm_consensus_score=0.0
            )
    
    async def _create_selection_report(self, decision: SelectionDecision):
        """é¸æŠãƒ¬ãƒãƒ¼ãƒˆä½œæˆãƒ»GitHub IssueæŠ•ç¨¿"""
        
        try:
            # ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ç”Ÿæˆ
            report_content = self._generate_selection_report_content(decision)
            
            # GitHub Issueä½œæˆ
            issue_data = await self.atomic_operations.create_issue(
                title=f"ğŸ¯ ç«¶æŠ€é¸æŠæ±ºå®š - {decision.strategy.value} ({len(decision.selected_competitions)}ç«¶æŠ€)",
                description=report_content,
                labels=["competition-selection", "decision", f"strategy-{decision.strategy.value}"]
            )
            
            self.logger.info(f"é¸æŠãƒ¬ãƒãƒ¼ãƒˆä½œæˆå®Œäº†: Issue #{issue_data['number']}")
            
        except Exception as e:
            self.logger.error(f"é¸æŠãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _generate_selection_report_content(self, decision: SelectionDecision) -> str:
        """é¸æŠãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ç”Ÿæˆ"""
        
        # æˆ¦ç•¥ã‚¢ã‚¤ã‚³ãƒ³
        strategy_icons = {
            SelectionStrategy.CONSERVATIVE: "ğŸ›¡ï¸",
            SelectionStrategy.BALANCED: "âš–ï¸",
            SelectionStrategy.AGGRESSIVE: "ğŸš€",
            SelectionStrategy.PORTFOLIO_OPTIMAL: "ğŸ“Š"
        }
        
        strategy_icon = strategy_icons.get(decision.strategy, "ğŸ¯")
        
        content = f"""# {strategy_icon} Kaggleç«¶æŠ€é¸æŠæ±ºå®šãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“‹ æ±ºå®šã‚µãƒãƒªãƒ¼
- **æ±ºå®šID**: `{decision.decision_id}`
- **æ±ºå®šæ™‚åˆ»**: {decision.timestamp.isoformat()}
- **é¸æŠæˆ¦ç•¥**: {strategy_icon} {decision.strategy.value}
- **æ±ºå®šä¿¡é ¼åº¦**: {decision.decision_confidence:.1%}
- **LLMã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹**: {decision.llm_consensus_score:.1%}

## ğŸ† é¸æŠçµæœ
### âœ… é¸æŠç«¶æŠ€ ({len(decision.selected_competitions)}ç«¶æŠ€)
{chr(10).join([
    f"**{i+1}. {comp.name}**"
    f"  - ç¨®é¡: {comp.type} | ãƒ¡ãƒ€ãƒ«ç¢ºç‡: {comp.medal_probability:.1%}"
    f"  - LLMæ¨å¥¨: {comp.llm_recommendation} (ã‚¹ã‚³ã‚¢: {comp.llm_score:.2f})"
    f"  - GPUæ™‚é–“: {comp.estimated_gpu_hours:.1f}h | é–‹ç™ºæœŸé–“: {comp.estimated_development_days:.1f}æ—¥"
    f"  - ç· åˆ‡: {comp.deadline.strftime('%Y-%m-%d')} ({(comp.deadline - datetime.utcnow()).days}æ—¥å¾Œ)"
    for i, comp in enumerate(decision.selected_competitions)
]) if decision.selected_competitions else "ãªã—"}

### âŒ å´ä¸‹ç«¶æŠ€ ({len(decision.rejected_competitions)}ç«¶æŠ€)
{chr(10).join([
    f"- **{comp.name}**: {comp.llm_recommendation} | ãƒ¡ãƒ€ãƒ«ç¢ºç‡{comp.medal_probability:.1%}"
    for comp in decision.rejected_competitions[:5]  # ä¸Šä½5å€‹ã®ã¿è¡¨ç¤º
]) if decision.rejected_competitions else "ãªã—"}

### â¸ï¸ ä¿ç•™ç«¶æŠ€ ({len(decision.deferred_competitions)}ç«¶æŠ€)
{chr(10).join([
    f"- **{comp.name}**: {comp.llm_recommendation} | ãƒ¡ãƒ€ãƒ«ç¢ºç‡{comp.medal_probability:.1%}"
    for comp in decision.deferred_competitions[:5]  # ä¸Šä½5å€‹ã®ã¿è¡¨ç¤º
]) if decision.deferred_competitions else "ãªã—"}

## ğŸ“Š ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æ
### æœŸå¾…æˆæœ
- **äºˆæƒ³ãƒ¡ãƒ€ãƒ«æ•°**: {decision.expected_medal_count:.2f}å€‹
- **ç·æˆ¦ç•¥çš„ä¾¡å€¤**: {decision.total_expected_value:.2f}
- **ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯**: {decision.portfolio_risk_score:.2f}

### ãƒªã‚½ãƒ¼ã‚¹é…åˆ†
- **ç·GPUæ™‚é–“**: {decision.resource_allocation.get('total_gpu_hours', 0):.1f}æ™‚é–“ / {self.max_total_gpu_budget}æ™‚é–“
- **GPUåˆ©ç”¨ç‡**: {decision.resource_allocation.get('gpu_utilization', 0):.1%}
- **å¹³å‡é–‹ç™ºæœŸé–“**: {decision.resource_allocation.get('avg_development_days', 0):.1f}æ—¥

## ğŸ§  LLMè©•ä¾¡è©³ç´°
{chr(10).join([
    f"### {comp.name}"
    f"- **æ¨å¥¨**: {comp.llm_recommendation} (ã‚¹ã‚³ã‚¢: {comp.llm_score:.2f})"
    f"- **ç†ç”±**: {', '.join(comp.llm_reasoning[:3])}"  # ä¸Šä½3ã¤ã®ç†ç”±
    for comp in decision.selected_competitions
]) if decision.selected_competitions else "é¸æŠç«¶æŠ€ãªã—"}

## ğŸ¯ é¸æŠç†ç”±
{chr(10).join([f"- {reason}" for reason in decision.selection_reasoning])}

## ğŸ“ˆ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–çµæœ
```json
{json.dumps(decision.portfolio_optimization, indent=2, default=str)}
```

---
*è‡ªå‹•ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ | Competition Selector Agent `{self.agent_id}` | {datetime.utcnow().isoformat()}*"""

        return content
    
    async def get_current_portfolio_status(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªçŠ¶æ…‹å–å¾—"""
        
        current_time = datetime.utcnow()
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ç«¶æŠ€çµ±è¨ˆ
        active_competitions = [comp for comp in self.current_portfolio if comp.deadline > current_time]
        expired_competitions = [comp for comp in self.current_portfolio if comp.deadline <= current_time]
        
        if active_competitions:
            total_medal_probability = sum(comp.medal_probability for comp in active_competitions)
            total_gpu_hours = sum(comp.estimated_gpu_hours for comp in active_competitions)
            avg_confidence = sum(comp.confidence_level for comp in active_competitions) / len(active_competitions)
            type_distribution = {}
            for comp in active_competitions:
                type_distribution[comp.type] = type_distribution.get(comp.type, 0) + 1
        else:
            total_medal_probability = total_gpu_hours = avg_confidence = 0.0
            type_distribution = {}
        
        return {
            "agent_id": self.agent_id,
            "portfolio_last_updated": self.selection_history[-1].timestamp.isoformat() if self.selection_history else None,
            "active_competitions_count": len(active_competitions),
            "expired_competitions_count": len(expired_competitions),
            "total_medal_probability": total_medal_probability,
            "total_gpu_hours_allocated": total_gpu_hours,
            "gpu_budget_utilization": total_gpu_hours / self.max_total_gpu_budget,
            "avg_confidence_level": avg_confidence,
            "type_distribution": type_distribution,
            "selection_decisions_made": len(self.selection_history),
            "last_selection_strategy": self.selection_history[-1].strategy.value if self.selection_history else None,
            "active_competitions": [
                {
                    "name": comp.name,
                    "type": comp.type,
                    "medal_probability": comp.medal_probability,
                    "days_remaining": (comp.deadline - current_time).days,
                    "llm_recommendation": comp.llm_recommendation
                }
                for comp in active_competitions
            ]
        }
    
    async def update_competition_performance(self, competition_id: str, actual_result: Dict[str, Any]):
        """ç«¶æŠ€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ›´æ–°ï¼ˆå­¦ç¿’ç”¨ï¼‰"""
        
        try:
            # å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’å±¥æ­´ã«è¨˜éŒ²
            if competition_id not in self.historical_performance:
                self.historical_performance[competition_id] = []
            
            performance_record = {
                "timestamp": datetime.utcnow().isoformat(),
                "competition_id": competition_id,
                "actual_result": actual_result,
                "predicted_medal_probability": None,
                "predicted_strategic_value": None
            }
            
            # äºˆæ¸¬å€¤ã‚‚è¨˜éŒ²ï¼ˆå¯¾å¿œã™ã‚‹é¸æŠæ±ºå®šã‹ã‚‰å–å¾—ï¼‰
            for decision in self.selection_history:
                for comp in decision.selected_competitions:
                    if comp.id == competition_id:
                        performance_record["predicted_medal_probability"] = comp.medal_probability
                        performance_record["predicted_strategic_value"] = comp.strategic_value
                        break
            
            self.historical_performance[competition_id].append(performance_record)
            
            self.logger.info(f"ç«¶æŠ€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ›´æ–°: {competition_id}")
            
        except Exception as e:
            self.logger.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_selection_performance_metrics(self) -> Dict[str, Any]:
        """é¸æŠãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™å–å¾—"""
        
        if not self.historical_performance:
            return {"message": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å±¥æ­´ãªã—"}
        
        # ç²¾åº¦åˆ†æ
        total_predictions = 0
        correct_medal_predictions = 0
        
        for comp_id, records in self.historical_performance.items():
            for record in records:
                if record.get("predicted_medal_probability") is not None:
                    total_predictions += 1
                    
                    # å®Ÿéš›ã«ãƒ¡ãƒ€ãƒ«ã‚’ç²å¾—ã—ãŸã‹ãƒã‚§ãƒƒã‚¯
                    actual_medal = record["actual_result"].get("medal_achieved", False)
                    predicted_prob = record["predicted_medal_probability"]
                    
                    # ç¢ºç‡0.5ä»¥ä¸Šã‚’ã€Œãƒ¡ãƒ€ãƒ«äºˆæ¸¬ã€ã¨ã—ã¦æ‰±ã†
                    predicted_medal = predicted_prob >= 0.5
                    
                    if actual_medal == predicted_medal:
                        correct_medal_predictions += 1
        
        accuracy = correct_medal_predictions / max(1, total_predictions)
        
        return {
            "total_competitions_tracked": len(self.historical_performance),
            "total_predictions": total_predictions,
            "prediction_accuracy": accuracy,
            "selection_decisions_made": len(self.selection_history),
            "avg_competitions_per_decision": len(self.current_portfolio) / max(1, len(self.selection_history))
        }